{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44120ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (4.13.5)\n",
      "Requirement already satisfied: lxml in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (6.0.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from beautifulsoup4) (4.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniforge3/envs/bigram_env/lib/python3.10/site-packages (from requests) (2025.8.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch\n",
    "%pip install beautifulsoup4 lxml\n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff9e55",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93339a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scraping\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# for model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "import re\n",
    "\n",
    "# data steps:\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2d627",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf08fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_site_text(url: str, site: str, filename: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Scapes the main text from the website depending on site [\"marca\", \"as\", \"mundo\"] and saves as <filename>.txt\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/140.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        print('Error: Could not fetch page', response.status_code)\n",
    "        return None\n",
    "\n",
    "    soup = bs4(response.text, 'html.parser')\n",
    "\n",
    "    article_text = \"\"\n",
    "\n",
    "    match site:\n",
    "        case \"as\":\n",
    "            #using json-ld data\n",
    "            scripts = soup.find(\"script\", type=\"application/ld+json\")\n",
    "\n",
    "\n",
    "            for script in scripts:\n",
    "                if script and script.string:\n",
    "                    try:\n",
    "                        data = json.loads(script.string)\n",
    "                        items = data if isinstance(data, list) else [data]\n",
    "\n",
    "                        for item in items:\n",
    "                            if (isinstance(item, dict) and \n",
    "                                item.get(\"@type\") in [\"NewsArticle\", [\"NewsArticle\"]] and \n",
    "                                item.get(\"articleBody\")):\n",
    "\n",
    "                                filetxt = item.get(\"articleBody\").strip()\n",
    "                                with open(\"../articles/\" + filename+'.txt', 'w') as file:\n",
    "                                    file.write(filetxt)\n",
    "\n",
    "                                return filetxt\n",
    "                    except Exception as e:\n",
    "                        print(\"JSON parse error:\", e)\n",
    "                        return None\n",
    "        \n",
    "\n",
    "        case \"marca\":\n",
    "            article_body = soup.find(\"div\", class_=\"ue-c-article__body\")\n",
    "\n",
    "            if article_body:\n",
    "                paragraphs  = article_body.find_all(\"p\", class_ = \"ue-c-article__paragraph\")\n",
    "\n",
    "                if paragraphs:\n",
    "                    for para in paragraphs:\n",
    "                        para_text = para.get_text(strip = True)\n",
    "                        if(para_text):\n",
    "                            article_text = article_text + para_text\n",
    "\n",
    "\n",
    "                    filetxt = article_text.strip() if article_text else None\n",
    "                    with open(\"../articles/\" + filename+'.txt', 'w') as file:\n",
    "                        file.write(filetxt)\n",
    "\n",
    "                    return filetxt\n",
    "\n",
    "        case \"mundo\":\n",
    "            paragraphs  = soup.find_all(\"p\", class_ = \"paragraph\")\n",
    "\n",
    "            if paragraphs:\n",
    "                for para in paragraphs:\n",
    "                    para_text = para.get_text(strip = True)\n",
    "                    if(para_text):\n",
    "                        article_text = article_text + para_text\n",
    "                \n",
    "                filetxt = article_text.strip() if article_text else None\n",
    "                with open(\"../articles/\" + filename+'.txt', 'w') as file:\n",
    "                    file.write(filetxt)\n",
    "\n",
    "                return filetxt\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbf3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load and combine all article files:\n",
    "def combine_articles(combined_text=\"\") -> str:\n",
    "\n",
    "    for filename in os.listdir(\"../articles\"):\n",
    "        if(filename.endswith(\".txt\")):\n",
    "            with open(os.path.join(\"../articles\", filename), 'r', encoding = \"utf-8\") as f:\n",
    "                combined_text = combined_text + f.read() + \"\\n\\n\"\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb967afc",
   "metadata": {},
   "source": [
    "## Dataset and Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895a3f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramDataset(Dataset):\n",
    "\n",
    "    # need to overwrite __init__, __len__, and __getitem__ for DataLoader\n",
    "\n",
    "    def __init__(self, data, block_size = 128):\n",
    "        self.data = data\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.block_size]\n",
    "        y = self.data[idx + 1:idx+self.block_size + 1]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08f4a4",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24cb2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, idx):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        return logits\n",
    "    \n",
    "    def configure_optimizer(self):\n",
    "        \"\"\"\n",
    "        Using AdamW optimizer -> check optim_notes.txt\n",
    "        \"\"\"\n",
    "        return torch.optim.AdamW(self.parameters(), lr = 0.001)\n",
    "    \n",
    "    def training_step(self, input, target):\n",
    "        \"\"\"\n",
    "        1. Embed tokens -> get predictions for each token in the sequence\n",
    "        2. Flatten sequences into single batch -> required format for loss function\n",
    "        3. Compute cross-entropy loss\n",
    "        4. Return loss -> used to update weights with the optimizer\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        logits = self.token_embedding_table(input)\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = target.view(B*T)\n",
    "        loss = f.cross_entropy(logits, targets)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0):\n",
    "        \"\"\"\n",
    "        1. Start with an initial token sequence idx\n",
    "        2. For each new token to generate:\n",
    "            1. Predict Logits for all tokens in the vocab at the last position\n",
    "            2. Convert logits to probability using softmax\n",
    "            3. Sample a token from multinomial distribution\n",
    "            4. Apped the sampled token to the sequence\n",
    "        3. Repeat until max_new_tokens\n",
    "        4. Return the complete generated sentence\n",
    "        \"\"\"\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self.forward(idx)\n",
    "            logits = logits[:, -1, :] # take all sequences in batch, take only the last token in the sequence, take all vocab logits\n",
    "\n",
    "            # adding temperature\n",
    "            logits = logits/temperature\n",
    "\n",
    "            probabilities = f.softmax(logits, dim = -1)     \n",
    "            idx_next = torch.multinomial(probabilities, num_samples=1) # randomly picks an index according to probabilities\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0034f44",
   "metadata": {},
   "source": [
    "## Model initialization and main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "def main():\n",
    "    website_list = [\"https://www.marca.com/baloncesto/nba/2025/09/22/plan-lakers-nuevo-doncic-asaltar-nba-miman-luka-adelgazar-14-kilos.html\",\n",
    "                \"https://as.com/baloncesto/nba/la-retirada-esta-cerca-pero-aun-no-ha-llegado-n/\",\n",
    "                \"https://www.mundodeportivo.com/baloncesto/nba/20250926/1002539251/nueva-lesion-vuelve-golpear-sixers.html\"\n",
    "                ]\n",
    "    \n",
    "\n",
    "    scrape_site_text(website_list[0], \"marca\", \"lebron-retires\")\n",
    "    scrape_site_text(website_list[1], \"as\", \"lakers-and-luka\")\n",
    "    scrape_site_text(website_list[2], \"mundo\", \"sixers-new-injury\")\n",
    "\n",
    "\n",
    "    combined_text = combine_articles().lower()\n",
    "\n",
    "    words = re.findall(r'\\w+|\\S', combined_text)\n",
    "    counts = Counter(words)\n",
    "    words = [w if counts[w]>1 else \"<unk>\" for w in words]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # chars = sorted(list(set(combined_text)))\n",
    "    vocab = sorted(list(set(words)))\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    # mappings between text and numbers\n",
    "    stoi = {ch: i for i, ch in enumerate(vocab)}\n",
    "    itos = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "    # Encode the whole text\n",
    "    data = torch.tensor([stoi[w] for w in words], dtype=torch.long)\n",
    "\n",
    "\n",
    "    # Train/validation split\n",
    "\n",
    "    n = int(0.9 * len(data))\n",
    "\n",
    "    train_data = data[:n]           # first 90% \n",
    "    val_data = data[n:]             # last 10%\n",
    "\n",
    "    block_size = 8\n",
    "    train_dataset = BigramDataset(train_data, block_size)\n",
    "    val_dataset = BigramDataset(val_data, block_size)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle =True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "    model = BigramModel(vocab_size)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = 0.001)\n",
    "\n",
    "    # pre-training things:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    epochs = 30\n",
    "\n",
    "    # Training loop:\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x,y in train_loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(x)\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            y = y.view(B*T)\n",
    "            loss = f.cross_entropy(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss = total_loss + loss.item()\n",
    "        print(f\"Epoch: {epoch+1}, Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y, in val_loader:\n",
    "                x,y = x.to(device), y.to(device)\n",
    "                logits = model(x)\n",
    "                B, T, C = logits.shape\n",
    "                logits = logits.view(B*T, C)\n",
    "                y = y.view(B*T)\n",
    "                loss = f.cross_entropy(logits, y)\n",
    "                val_loss = val_loss + loss.item()\n",
    "        print(f\"Epoch: {epoch+1}, Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Generate Text:\n",
    "    start_word = \"el\" if \"el\" in stoi else vocab[0]\n",
    "    start = torch.tensor([[stoi[start_word]]], dtype=torch.long).to(device)\n",
    "\n",
    "    generated = model.generate(start, max_new_tokens=50, temperature=0.8)\n",
    "\n",
    "    #decode\n",
    "    \n",
    "    text_generated = ' '.join([itos[int(i)] for i in generated[0]])\n",
    "    print(\"Generated Text: \\n\")\n",
    "    print(text_generated)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d09ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 5.5320\n",
      "Epoch: 1, Val Loss: 5.5004\n",
      "Epoch: 2, Train Loss: 5.4736\n",
      "Epoch: 2, Val Loss: 5.4593\n",
      "Epoch: 3, Train Loss: 5.4208\n",
      "Epoch: 3, Val Loss: 5.4189\n",
      "Epoch: 4, Train Loss: 5.3655\n",
      "Epoch: 4, Val Loss: 5.3789\n",
      "Epoch: 5, Train Loss: 5.3090\n",
      "Epoch: 5, Val Loss: 5.3391\n",
      "Epoch: 6, Train Loss: 5.2563\n",
      "Epoch: 6, Val Loss: 5.2997\n",
      "Epoch: 7, Train Loss: 5.2048\n",
      "Epoch: 7, Val Loss: 5.2610\n",
      "Epoch: 8, Train Loss: 5.1527\n",
      "Epoch: 8, Val Loss: 5.2228\n",
      "Epoch: 9, Train Loss: 5.0980\n",
      "Epoch: 9, Val Loss: 5.1851\n",
      "Epoch: 10, Train Loss: 5.0472\n",
      "Epoch: 10, Val Loss: 5.1478\n",
      "Epoch: 11, Train Loss: 4.9943\n",
      "Epoch: 11, Val Loss: 5.1113\n",
      "Epoch: 12, Train Loss: 4.9457\n",
      "Epoch: 12, Val Loss: 5.0749\n",
      "Epoch: 13, Train Loss: 4.8953\n",
      "Epoch: 13, Val Loss: 5.0397\n",
      "Epoch: 14, Train Loss: 4.8486\n",
      "Epoch: 14, Val Loss: 5.0043\n",
      "Epoch: 15, Train Loss: 4.7979\n",
      "Epoch: 15, Val Loss: 4.9697\n",
      "Epoch: 16, Train Loss: 4.7483\n",
      "Epoch: 16, Val Loss: 4.9358\n",
      "Epoch: 17, Train Loss: 4.7009\n",
      "Epoch: 17, Val Loss: 4.9021\n",
      "Epoch: 18, Train Loss: 4.6534\n",
      "Epoch: 18, Val Loss: 4.8694\n",
      "Epoch: 19, Train Loss: 4.6077\n",
      "Epoch: 19, Val Loss: 4.8370\n",
      "Epoch: 20, Train Loss: 4.5615\n",
      "Epoch: 20, Val Loss: 4.8052\n",
      "Epoch: 21, Train Loss: 4.5162\n",
      "Epoch: 21, Val Loss: 4.7740\n",
      "Epoch: 22, Train Loss: 4.4703\n",
      "Epoch: 22, Val Loss: 4.7431\n",
      "Epoch: 23, Train Loss: 4.4262\n",
      "Epoch: 23, Val Loss: 4.7130\n",
      "Epoch: 24, Train Loss: 4.3841\n",
      "Epoch: 24, Val Loss: 4.6832\n",
      "Epoch: 25, Train Loss: 4.3393\n",
      "Epoch: 25, Val Loss: 4.6547\n",
      "Epoch: 26, Train Loss: 4.2973\n",
      "Epoch: 26, Val Loss: 4.6262\n",
      "Epoch: 27, Train Loss: 4.2564\n",
      "Epoch: 27, Val Loss: 4.5986\n",
      "Epoch: 28, Train Loss: 4.2162\n",
      "Epoch: 28, Val Loss: 4.5714\n",
      "Epoch: 29, Train Loss: 4.1755\n",
      "Epoch: 29, Val Loss: 4.5448\n",
      "Epoch: 30, Train Loss: 4.1352\n",
      "Epoch: 30, Val Loss: 4.5190\n",
      "el rookie 2 perderse le rey sobre contra jugar edad / jugadores rookie pretemporada última leyenda nba menisco más lesión ex firmar jugadores 2 nueva medio contrato medio rookie lesión por años exterior una duda ya nba . mismo aprecio lebron si otra retirará <unk> historia y <unk> hecho ninguna contra\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigram_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
